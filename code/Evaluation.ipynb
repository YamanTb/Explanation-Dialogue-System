{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28940ad1-0316-4d04-a9ea-605f92f9567c",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "This notebook covers the automatic and human evaluations of our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c85f945-52ae-4c06-8294-58d712c7ea0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.8/dist-packages (0.3.13)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bert-score) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bert-score) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from bert-score) (4.27.0.dev0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from bert-score) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.8/dist-packages (from bert-score) (4.62.3)\n",
      "Requirement already satisfied: requests in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (2.1.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (2023.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (0.17.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (4.28.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from requests->bert-score) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from requests->bert-score) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/ceph/storage/data-tmp/2022/yaman-rtb/.local/lib/python3.8/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.21.5)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge-score) (3.6.6)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (4.62.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install all the required packages.\n",
    "%pip install bert-score\n",
    "!pip install rouge-score\n",
    "!pip install scipy\n",
    "import pandas as pd\n",
    "from bert_score import BERTScorer\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200d5e80-e742-460e-8c15-077bd4670467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "df_test_results = pd.read_pickle('../test_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe75a86-0a7d-4fcf-af62-e60dec3b783a",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae134364-761c-489a-8d02-684c577565eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize BERT-Score object\n",
    "scorer = BERTScorer(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318d15a-755e-4bfd-95aa-755a9518102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate BERT-Score for each turn in each dialogue of testset\n",
    "# one time Groundtrouth vs. Aproach, second time Groundtrouth vs. Basline\n",
    "df_test_results['bert_score'] = df_test_results['results'].map(lambda l: list(map(lambda e: [scorer.score([e[1]],[e[2]]), scorer.score([e[1]],[e[3]])], l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dae02f-3b35-4e07-8411-7807c2c0f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_avg_bert_score_Approach for one dialogue\n",
    "def calculate_avg_bert_score_Approach(row):\n",
    "    cnt, res = 0, 0\n",
    "    for (p1, r1, f11), (p2, r2, f12) in row:\n",
    "        cnt += 1   \n",
    "        res += f11 #Approach\n",
    "    return res/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e4e1d-9c0e-4b51-81a3-5a4ac309e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_avg_bert_score_Basline for one dialogue\n",
    "def calculate_avg_bert_score_Basline(row):\n",
    "    cnt, res = 0, 0\n",
    "    for (p1, r1, f11), (p2, r2, f12) in row:\n",
    "        cnt += 1   \n",
    "        res += f12 #Basline\n",
    "    return res/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3774c6d-4243-49e9-a74e-3b926ec94c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BERT-Scores\n",
    "df_test_results['bert_score_avg_Ap'] = df_test_results['bert_score'].apply(calculate_avg_bert_score_Approach)\n",
    "df_test_results['bert_score_avg_BL'] = df_test_results['bert_score'].apply(calculate_avg_bert_score_Basline)\n",
    "df_test_results.bert_score_avg_Ap = df_test_results.bert_score_avg_Ap.apply(lambda l: l[0].item())\n",
    "df_test_results.bert_score_avg_BL = df_test_results.bert_score_avg_BL.apply(lambda l: l[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb5f43-6e5e-41e5-b65d-58bd5624b924",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae34d44-a60b-4663-97cd-2863b0becb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROUGE scores\n",
    "rg_scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "df_test_results['rouge_score_Approach'] = df_test_results['results'].map(lambda l: list(map(lambda e: rg_scorer.score(e[1],e[2])['rouge1'][2], l)))\n",
    "df_test_results['rouge_score_Basline'] = df_test_results['results'].map(lambda l: list(map(lambda e: rg_scorer.score(e[1],e[3])['rouge1'][2], l)))\n",
    "df_test_results['Rouge_Score_Avg_Approach'] = df_test_results['rouge_score_Approach'].map(lambda l: sum(l)/len(l))\n",
    "df_test_results['Rouge_Score_Avg_Basline'] = df_test_results['rouge_score_Basline'].map(lambda l: sum(l)/len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d19b2-e62c-4267-a3c2-aafd5830a4b3",
   "metadata": {},
   "source": [
    "## Summary of Automatic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7ec01-970d-4278-8fd0-f5d537fdd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results[['bert_score_avg_Ap', 'bert_score_avg_BL', 'Rouge_Score_Avg_Approach', 'Rouge_Score_Avg_Basline']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086e00f-0b2b-4a7c-a2ab-5be1c30cdc81",
   "metadata": {},
   "source": [
    "## Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93390c4-a967-4bf9-a9ff-8d025a6cb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the data of human evaluation\n",
    "U1 = [ \n",
    "    1, 3, 2, 1, 3, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 2, 1, 3, 2, 3, 1, 3, 2, 1, 1,\n",
    "    3, 2, 2, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 2, 3, 1, 3, 2, 2, 3, 1, 1, 2,\n",
    "    3, 2, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 2, 3, 1, 3, 2, 1,\n",
    "    1, 2, 3, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 1, 2\n",
    "]\n",
    "U2 = [\n",
    "    1, 3, 2, 1, 3, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 1, 3, 2, 1, 2, 3, 3, 1, 2, 1,\n",
    "    2, 3, 1, 3, 2, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 2, 3, 1, 1, 2,\n",
    "    3, 2, 1, 3, 1, 3, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 2, 1, 3, 1, 3, 2, 1, 3, 2,\n",
    "    1, 3, 2, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1, 3, 2\n",
    "]\n",
    "U3 = [ \n",
    "    1, 3, 2, 1, 2, 3, 3, 2, 1, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1,\n",
    "    2, 3, 1, 2, 3, 3, 2, 1, 2, 1, 3, 2, 3, 1, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2,\n",
    "    3, 1, 3, 2, 3, 1, 2, 1, 2, 3, 2, 1, 3, 3, 1, 2, 3, 1, 2, 2, 3, 1, 1, 3, 2,\n",
    "    1, 3, 2, 2, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2\n",
    "]\n",
    "\n",
    "U4 = [ \n",
    "    1, 2, 3, 1, 3, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 3, 2, 1,\n",
    "    3, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 2, 1, 3, 3, 1, 2, 1, 2, 3, 2, 3, 1, 1, 2,\n",
    "    3, 3, 2, 1, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1, 3, 2, 2, 3, 1,\n",
    "    1, 2, 3, 3, 2, 1, 3, 2, 1, 2, 1, 3, 3, 1, 2\n",
    "]\n",
    "U5 = [ \n",
    "    1, 3, 2, 1, 2, 3, 3, 1, 2, 3, 2, 1, 3, 2, 1, 1, 3, 2, 3, 2, 1, 3, 1, 2, 1,\n",
    "    3, 2, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 3, 1, 2, 1, 3, 2, 2, 3, 1, 1, 2,\n",
    "    3, 2, 1, 3, 3, 1, 2, 3, 1, 2, 2, 1, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 1, 3, 2,\n",
    "    2, 1, 3, 3, 1, 2, 2, 1, 3, 3, 2, 1, 3, 1, 2\n",
    "]\n",
    "U6 = [\n",
    "    1, 3, 2, 1, 2, 3, 3, 2, 1, 3, 2, 1, 1, 2, 3, 1, 2, 3, 2, 3, 1, 1, 2, 3, 1,\n",
    "    2, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 3, 2, 2, 1, 3, 2, 1, 3, 1, 3, 2, 2, 1,\n",
    "    3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 2, 1, 3, 1, 2, 3, 3, 1, 2, 2, 3, 1, 1, 3, 2,\n",
    "    2, 1, 3, 3, 1, 2, 2, 1, 3, 3, 1, 2, 3, 1, 2\n",
    "]\n",
    "U7 = [\n",
    "    1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 1, 1, 2, 3, 2, 3, 1, 1, 2, 3, 3, 2, 1, 1,\n",
    "    2, 3, 3, 1, 2, 3, 2, 1, 3, 1, 2, 1, 2, 3, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1,\n",
    "    3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 3, 2, 1, 2, 3, 3, 2, 1, 2, 3, 1, 1, 3, 2,\n",
    "    1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3\n",
    "]\n",
    "U8 = [\n",
    "    2, 1, 3, 1, 2, 3, 3, 2, 1, 3, 2, 1, 2, 1, 3, 1, 2, 3, 3, 2, 1, 2, 1, 3, 1,\n",
    "    2, 3, 1, 2, 3, 3, 2, 1, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1, 2, 3, 3, 2, 1, 1, 2,\n",
    "    3, 1, 3, 2, 3, 1, 2, 3, 1, 2, 2, 1, 3, 1, 3, 2, 2, 1, 3, 2, 3, 1, 2, 3, 1,\n",
    "    1, 2, 3, 3, 2, 1, 1, 2, 3, 1, 2, 3, 1, 3, 2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a696e1f-188d-45f6-88b2-b5e315717d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Kendall Tau correlation coefficients for all pairs of arrays and calculate the average for all pairs\n",
    "array_names = [\"U1\", \"U2\", \"U3\", \"U4\", \"U5\", \"U6\", \"U7\", \"U8\"]\n",
    "arrays = [U1, U2, U3, U4, U5, U6, U7, U8]\n",
    "\n",
    "kendall_tau_results = []\n",
    "\n",
    "for i in range(len(arrays) - 1):\n",
    "    for j in range(i + 1, len(arrays)):\n",
    "        kendall_tau = scipy.stats.kendalltau(arrays[i], arrays[j])\n",
    "        kendall_tau_results.append(kendall_tau.correlation)\n",
    "        print(kendall_tau.correlation)\n",
    "\n",
    "average_kendall_tau = sum(kendall_tau_results) / len(kendall_tau_results)\n",
    "print(f\"Average Kendall Tau correlation coefficient for all pairs of arrays: {average_kendall_tau}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f391e4-1262-45db-bada-ecbf25bcf22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter the summary of Human Evaluation A (Groundtruth), B (Approach), C (Baseline)\n",
    "\n",
    "human_eval_summary = {\n",
    "#               A , B , C\n",
    "    'Rank 1': [109, 69, 62],\n",
    "    'Rank 2': [56, 104, 80],\n",
    "    'Rank 3': [75, 67, 98]\n",
    "}\n",
    "\n",
    "# Define the index labels\n",
    "index_labels = ['Groundtruth', 'Approach', 'Baseline']\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df_human_eval_summary = pd.DataFrame(human_eval_summary, index=index_labels)\n",
    "\n",
    "# To display the DataFrame, you can use\n",
    "print(df_human_eval_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f14b62-f6b8-4a93-99ce-8fdc1e8de4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart using the DataFrame `df`\n",
    "ax = df_human_eval_summary.T.plot(kind='bar', figsize=(10, 7), colormap='tab20c')\n",
    "\n",
    "\n",
    "# Set the title and labels\n",
    "# ax.set_title('Comparison of Results of Human Evaluation')\n",
    "ax.set_xlabel('Turn Rank')\n",
    "plt.xticks(rotation=0)\n",
    "# ax.set_ylabel('Occurrences')\n",
    "ax.set_ylim([0, 125])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
